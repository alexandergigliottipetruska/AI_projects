# IRIS Dataset Classification
The classification of the IRIS dataset involved using four features (petal length, petal width, sepal length, and sepal width) to predict the IRIS flower species (setosa, versicolor, or virginica). Despite the simplicity and size of the dataset, the main purpose was to carry out my first project in machine learning from importing the data all the way to evaluating it on a test set. Nevertheless, there were more concrete goals as well, such as a focus on exploratory data analysis, data visualization, data preprocessing, feature engineering, classification metrics, and a deepened acquaintance with libraries such as scikit-learn, pandas, and matplotlib. Moreover, the implementation of a logistic regression (softmax) model from scratch, using the knowledge I had acquired from CSC311, with its loss (categorical cross-entropy), regularization, and gradient descent algorithm, was an important achievement. Finally, the goal was to reach at least a 90% accuracy on the test set.

From this project, I can say that I gained a deeper appreciation of the importance of EDA, feature scaling, and data visualization. Not only do these improve one's understanding of the data, but they also give a preliminary idea of which models will likely perform the best on the dataset. For example, kNN outperformed logistic regression on the test dataset as the dataset was not linearly separable, due to the closeness between the sepal length and width among all three classes. Using confusion matrices and other classification metrics in analyzing the test set results further confirmed these observations as the model's mistakes were centered on the differences between virginica and versicolor flowers. In addition, implementing the logistic regression algorithm helped me solidify concepts taught in class and extend their application to real projects, particularly gradient descent, categorically cross entropy, and regularization, and the softmax function.

## üá´üá∑
La classification de l'IRIS jeu de donn√©es concerne quatre caract√©ristiques (la longueur des p√©tales, la largeur des p√©tales, la longeuer des s√©pales, et la largeur des s√©pales) pour pr√©dire l'esp√®ce des fleurs (setosa, versicolor, ou virginica). Malgr√© sa simplicit√© et sa dimension, mon but principal √©tait de faire mon premier project en apprentissage automatique, d'importer les donn√©es √† √©valuer mon mod√®le sur un jeu de test. N√©anmoins, il y avait d'autres objectifs qui √©taient plus concrets, comme l'analyse exploratoire des donn√©es, la visualisation des donn√©es, le pr√©traitement des donn√©es, l'ing√©nierie des caract√©ristiques, les m√©triques de classification, et une connaissance des biblioth√©ques essentielles - scikit-learn, pandas, et matplotlib. De plus, l'implementation d'une r√©gression logistique (softmax) √† partir de z√©ro, en utilisant le savoir que j'ai obtenu du CSC311, avec sa fonction de perte (entropie crois√©e cat√©gorielle), la r√©gularisation, et la descente de gradient, √©tait un accomplissement important. Finalement, je voulais obtenir une pr√©cision d'au moins 90% sur le jeu de test.

Gr√¢ce a ce project, j'ai atteint une appr√©ciation de l'importance d'EDA, la normalisation des caract√©ristiques, et la visualisation des donn√©es. Ils ne sont pas seulement essentiels pour la comprehension des donn√©es, mais aussi pour se faire une id√©e pr√©liminaire des mod√®les qui pourraient le mieux convenir. Par exemple, kNN superperforme la r√©gression logistique sur le jeu de test car les donn√©es ne √©taient pas lin√©airement s√©parable, √† cause de la proximit√© entre la longueur des s√©pales et la largeur des s√©pales parmi les trois classes. La utilisation de la matrice de confusion et autres m√©triques de classification m'a permis d'analyser les r√©sultats et confirmer les observations que les erreurs du mod√®le √©taient centr√©es sur les diff√©rences entre la fleur virginca et la fleur versicolor. En outre, l'implementation de la r√©gression logistique m'ai aid√© solidifier les concepts qui √©taient enseign√©s en class.

