# My Deep Learning Journey
In order to document and track my progression through studying Deep Learning, I've created this github repository as a track and review all of my failures and succcesses, my experiments and results, over the following year. As I have been learning French, I have made this github both in French and English, and hopefully in a manner that is clear and comprehensible to anyone who reads either language. Please feel free to correct my French, if I make any mistakes, as I will be studying intensely in Paris this entire summer, and I wish to improve. Finally, the objective of my studies is to create and research new technologies.

Here is a table I generated using GPT that captures the complexity of building each model by hand. When I say the models have been built 'by hand', I mean that the only tools I have used are the numpy library for linear algebra operations and the mathematical equations of these models. It also functions as a checklist, with the date under Completed being the day I finished the implementation of the model, and underlined example models being the ones I concretely implemented. Of course, I do not expect to be anywhere near building all of these by hand by the end of the summer, but I hope to have at least gone through a significant portion of this checklist. Moreover, every built model is accompanied with a corresponding project that demonstrates its capicity and performance against library models. Finally, some projects will have two models if the task for which I am building them is very similar (for example, a clustering unsupervised learning task will have both the clustering and expectation-maximization algorithms implemented). Feel free to copy the table for your own projects.

| Rank  | Model Type | Example Models | Complexity | Completed? |  
| ------------- | ------------- | ------------  | ------------- | -
| 1 | Linear Models  | <ins>Linear Regression, LASSO, Ridge Regression and Logistic Regression</ins> | ğŸŸ¢ Easiest  | âœ”ï¸07/05/2025 |
| 2 | Instance-Based | <ins>KNN</ins>  | ğŸŸ¢ Easy | âœ”ï¸09/05/2025 |
| 3 | Probabilistic | Naive Bayes | ğŸŸ¢ Easy  |  | 
| 4 | Dimensionality Reduction | PCA | ğŸŸ¢ Easy  | Current focus | 
| 5 | Clustering  | <ins>K-Means</ins> | ğŸŸ¢â€“ğŸŸ  Easy-Med | âœ”ï¸12/05/2025 | 
| 6 | Probabilistic Clustering  | Expectation-Maximization | ğŸŸ  Medium |  | 
| 7 | Tree-Based | Decision Trees | ğŸŸ  Medium  | On pause | 
| 8 | Margin-Based  | SVM | ğŸŸ â€“ğŸ”´ Medium-Hard  |  | 
| 9 | Ensemble  | Random Forest, XGBoost | ğŸ”´ Hard  |  | 
| 10 | Neural Networks  | <ins>Shallow NN</ins> | ğŸŸ  Medium  | âœ”ï¸18/05/2025 | 
| 11 | CNNs  | Vanilla CNN, LeNet, VGG| ğŸ”´ Hard  | Starting soon (22/05/2025) | 
| 12 | RNNs  | Vanilla RNN | ğŸ”´ Hard  |  | 
| 13 | LSTM/GRU  | Seq2Seq | ğŸ”´â€“ğŸš¨ Hard-Very Hard  |  | 
| 14 | Transformer  | Vanilla Transformer, BERT, GPT | ğŸš¨ Very Hard  |  | 
| 15 | LLM  | GPT-3, PaLM | ğŸ§  Expert-only |  | 

Thank you for your time and attention.
