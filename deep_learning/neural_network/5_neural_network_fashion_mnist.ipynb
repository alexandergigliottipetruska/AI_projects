{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST Neural Network\n",
        "\n",
        "Undertaking a classification task, the aim of this project is to develop skills in building neural networks from scratch, image preprocessing, and data augmentation. The dataset used is the Fashion MNIST dataset, which requires classifying instances into one of 10 different classes representing different clothing articles.\n",
        "\n",
        "The key learning goals of this project understanding backpropagation, loss, training loop, and gradients. Nevertheless, other features will be added that will develop other skills as well.\n",
        "\n",
        "**Main Objectives**:\n",
        "- Importing the Data\n",
        "- Cleaning the Data\n",
        "- Train/Test/Split\n",
        "- Exploratory Data Analysis (EDA) and Visualization\n",
        "- Preprocessing the Data\n",
        "- Data Augmentation\n",
        "- Training the Model\n",
        "- Hyperparameter Tuning\n",
        "- Test set evaluation\n",
        "- Metrics for performance - F1 score, precision, recall, confusion_matrix.\n",
        "- Finding out what kind of images the model's most confident wrong and correct predictions corresponded to, as well as it's most uncertain predictions.\n",
        "\n",
        "**Extra**:\n",
        "- Implement a **Neural Network** from scratch.\n",
        "- The network must have 1 input layer, 2 hidden layers, and an output layer.\n",
        "- Implement the forward propagation and backpropagation algorithms.\n",
        "- Use mini-batch gradient descent.\n",
        "- Implement the Adam optimizer, dropout, and layer normalization.\n",
        "- Add zerograd\n",
        "- Regularization with weight decay.\n",
        "- Softmax + Categorical Cross-Entropy\n",
        "- Early Stopping\n",
        "- Learning rate scheduler and momentum\n",
        "- Visualize loss curves\n",
        "- Implement ReLU\n",
        "- Modular design: Linear, ReLU, Dropout, and Softmax as separate classes.\n"
      ],
      "metadata": {
        "id": "DRnffAxX96MN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "KPTKkriF-ESN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Implementation\n",
        "\n",
        "The implementation of a non-modular neural network.\n",
        "\n",
        "This neural network will consist of an input layer, two hidden layers, and an output layer. Forward pass and backpropagation will be based on this model architecture, but this will change with the modular setup.\n",
        "\n",
        "Mini-batch gradient descent with Adam will be used for optimization.\n",
        "\n",
        "Dropout and weight decay will be used as regularizatoin.\n",
        "\n",
        "Early stopping, learning rate scheduler, and momentum will all be used to help convergence. Layer normalization will be added as well.\n",
        "\n",
        "Lastly, the softmax and ReLU activation functions have been implemented.\n",
        "\n",
        "Dimensions (for entire dataset):\n",
        "- $X$ = D x N\n",
        "- $W^{(1)}$ = L x D  \n",
        "- $b^{(1)}$ = L x 1\n",
        "- $m$ = L x N\n",
        "- $h$ = L x N\n",
        "- $W^{(2)}$ = K x L\n",
        "- $b^{(2)}$ = K x 1\n",
        "- $z$ = K x N\n",
        "- $y$ = K x N <br>\n",
        "\n",
        "The forward\n",
        "\n",
        "**Forward Propagation:**\n",
        "$$m = W^{(1)}x + b^{(1)}$$\n",
        "$$h = ReLU(m)$$\n",
        "$$z = W^{(2)}h + b^{(2)}$$\n",
        "$$y = softmax(z)$$\n",
        "$$L = L_{CE}(y, t)$$<br>\n",
        "\n",
        "**Backpropagation:**\n",
        "\n",
        "For the a batch of data, the forward pass and backpropagation will look like:\n"
      ],
      "metadata": {
        "id": "hrAkrkEC8MvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "  \"\"\"\n",
        "  TBD\n",
        "  \"\"\"\n",
        "  def __init__(self, dropout=0.8, learning_rate=0.01, regularization=None, lamb=0.2, batch_size=32, momentum=0.9):\n",
        "    self.W1 = None\n",
        "    self.W2 = None\n",
        "    self.b1 = None\n",
        "    self.b2 = None\n",
        "    self.momentum = momentum\n",
        "    self.batch_size = batch_size\n",
        "    self.dropout = dropout\n",
        "    self.learning_rate = learning_rate\n",
        "    self.regularization = regularization\n",
        "    self.lamb = lamb\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    pass\n",
        "\n",
        "  def forward_prop(self):\n",
        "    pass\n",
        "\n",
        "  def backwardpropagation(self):\n",
        "    pass\n",
        "\n",
        "  def gradient_descent(self):\n",
        "    pass\n",
        "\n",
        "  def compute_loss(self):\n",
        "    pass\n",
        "\n",
        "  def Adam_opitimizer(self):\n",
        "    pass\n",
        "\n",
        "  def predict(self):\n",
        "    pass\n",
        "\n",
        "  def relu(self, o):\n",
        "    return np.maximum(0, o)\n",
        "\n",
        "  def softmax(self, o):\n",
        "    # Softmax function implementation, the keepdims is used for broadcasting purposes.\n",
        "    z =  np.exp(o) / np.sum(np.exp(o), axis=1, keepdims=True)\n",
        "    return z\n",
        "\n",
        "  def mini_batch(self, t, X, N):\n",
        "    batches = {}\n",
        "    n_batches = N // self.batch_size\n",
        "    # Create batches\n",
        "    for i in range(n_batches):\n",
        "        batches[i] = [X[i*self.batch_size:(i+1)*self.batch_size], t[i*self.batch_size:(i+1)*self.batch_size]]\n",
        "\n",
        "    # Last batch should be compiled into its own batch, even if it's less than batch size\n",
        "    if N % self.batch_size != 0 :\n",
        "        batches[n_batches] = [X[n_batches*self.batch_size:], t[n_batches*self.batch_size:]]\n",
        "\n",
        "    return batches\n",
        "\n",
        "  def layer_normalization(self):\n",
        "    pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Spl0bU8cAqtZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modular Implementation of a Neural Network\n",
        "\n",
        "Divides the previous implementation k into several classes that can be combined to form the entire network. The main purpose of this is start writing modular code and create reusable classes for further projects."
      ],
      "metadata": {
        "id": "TwlLZ61Xp0Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kRXAdADc9LV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Data"
      ],
      "metadata": {
        "id": "u5GAHLEJqCs3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5l6P7TD5qDv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test/Split"
      ],
      "metadata": {
        "id": "i5qXZ5l3qEKG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-5dxRXLqGj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "ysnExHoQqHF3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hCcx1b2vqJF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Common techniques for augmenting images are the following:\n",
        "- tbd"
      ],
      "metadata": {
        "id": "jXykmB68qM4d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZKe43OkyqP2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "87qr4mIbqJmR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-r0UUqB6qLzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Model"
      ],
      "metadata": {
        "id": "t9qe4wPrqU4b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kj2-uIx8qWMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "Lj_CAXmQqXGE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aDsdr71dqY1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set Evaluation"
      ],
      "metadata": {
        "id": "ZbK_RhSRqZUR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kFc7KYI8qa4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Metrics"
      ],
      "metadata": {
        "id": "SqsiJ1YwqdJk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZQPsMsAqfyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of Model Prediction"
      ],
      "metadata": {
        "id": "w_sxAk5cqgMG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sm28vBbpqiTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing of Implementations"
      ],
      "metadata": {
        "id": "66TYn02VqiqL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkVPfjA4qken"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}